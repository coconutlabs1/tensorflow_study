# -*- coding: utf-8 -*-
"""texts_to_sequence.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k0H409HXlr48eHfufyVTmD7ZUBSt0dCw
"""

from tensorflow.keras.preprocessing.text import Tokenizer

sentences = [
             'i love my cat',
             'I love my car',
             'You love your dog!'
]

tokenizer = Tokenizer(num_words = 100)
tokenizer.fit_on_texts(sentences)
word_index = tokenizer.word_index
print(word_index)

sentences = tokenizer.texts_to_sequences(sentences)

print(sentences)

